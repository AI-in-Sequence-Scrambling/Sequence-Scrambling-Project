{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import required python packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import importlib\n",
    "import statistics\n",
    "import time\n",
    "from sklearn import metrics\n",
    "from skmultiflow.data.data_stream import DataStream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import helper scripts\n",
    "from helper_functions import keras_NN\n",
    "from helper_functions import methods_sampling\n",
    "from helper_functions import control_methods\n",
    "from helper_functions import SQA_preprocessing\n",
    "from helper_functions import params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "df_sqa = pd.read_csv(params.filepath_project_folder + '\\SQA_full_prepro_data.csv', index_col=0)\n",
    "df_features_kaco = pd.read_csv(params.filepath_project_folder  + '\\\\features_kaco.csv', index_col=0)\n",
    "df_A600 = pd.read_csv(params.filepath_project_folder + '\\extra_features\\A600_Date.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "target_col = 'delta_A600_E100'\n",
    "threshold = 400\n",
    "\n",
    "# Binarize target label\n",
    "df_SQA_cat = SQA_preprocessing.get_binary_SQA_Cats(df_sqa, target_col, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join features and label\n",
    "data_full = df_features_kaco.join(df_SQA_cat['delta_A600_E100_cat']).join(df_A600)\n",
    "data_full.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort dataset chronologically\n",
    "data_full = data_full.sort_values(by='Datetime_A600')\n",
    "data_full.drop(['Datetime_A600'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cut-away first and last 2000 samples\n",
    "data_full = data_full.astype(int)\n",
    "data_full = data_full.iloc[2000:-2000,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method to call the method to get an initialized aNN classifier\n",
    "importlib.reload(control_methods)\n",
    "def get_clf ():\n",
    "    input_shape = len(df_features_kaco.columns)\n",
    "    clf = control_methods.get_binary_NN_clf(input_shape)\n",
    "    \n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put the dataset into a stream and start the stream\n",
    "stream = DataStream(data_full)\n",
    "stream.prepare_for_use()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many samples in the stream?\n",
    "stream.n_remaining_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method to calculate statistics for the page-hickley-test\n",
    "sample_count = 1\n",
    "def compute_ph_statistics(mean_score, ph_sum, score, ph_sum_list):\n",
    "    # Compute new mean\n",
    "    mean_new = mean_score + ((score - mean_score) / sample_count)\n",
    "    \n",
    "    # Compute new sum of deviations\n",
    "    ph_sum_new = ph_sum + (score - mean_new)\n",
    "    ph_sum_list.append(ph_sum_new)\n",
    "    \n",
    "    # Compute change statistics\n",
    "    statistic_max = max(ph_sum_list) - ph_sum_new\n",
    "    statistic_min = ph_sum_new - min(ph_sum_list)\n",
    "    \n",
    "    return (mean_new, ph_sum_new, ph_sum_list, statistic_max, statistic_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function resets the values of the variables in case a drift is detected\n",
    "def reset_values():\n",
    "    ph_mean = 0\n",
    "    ph_sum = 0\n",
    "    ph_sum_list = []\n",
    "    sample_count = 1\n",
    "    return(ph_mean, ph_sum, ph_sum_list, sample_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters for the online learning model\n",
    "init_training = 50000\n",
    "retrain_batch_size = 20\n",
    "batch_size = 16\n",
    "epochs = 6\n",
    "C = 10\n",
    "iters = int((len(data_full)-init_training)/retrain_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method to perform sampling before training\n",
    "def sample(X, y):\n",
    "    df_x = pd.DataFrame(X)\n",
    "    df_y = pd.DataFrame(y)\n",
    "    df = df_x.join(df_y, rsuffix='_target')\n",
    "    df_sampled = methods_sampling.sample_data(df, '0_target', 'SMOTEENN')\n",
    "\n",
    "    return df_sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notrain scenario\n",
    "# Initialize\n",
    "sum = 0\n",
    "counter = 0\n",
    "iterator = 0\n",
    "X_list = []\n",
    "y_list = []\n",
    "\n",
    "# Initial training\n",
    "stream.restart()\n",
    "X, y = stream.next_sample(init_training)\n",
    "clf = get_clf()\n",
    "df_sampled = sample(X,y)\n",
    "clf.fit(df_sampled.iloc[:,:-1],df_sampled.iloc[:,-1:],batch_size = batch_size,epochs = 1)\n",
    "\n",
    "scores = []\n",
    "\n",
    "#Stream Simulation\n",
    "while (stream.n_remaining_samples() > 1):\n",
    "    # Get the next item from the stream\n",
    "    X, y = stream.next_sample(1)\n",
    "    X_list.append(X)\n",
    "    y_list.append(y)\n",
    "    \n",
    "    # Sum of the instances of the late class so far\n",
    "    sum = sum+y[0]\n",
    "    counter = counter + 1\n",
    "    \n",
    "    # Check if at least C instances per class are present\n",
    "    if (sum >= C) & (counter >= C):\n",
    "        counter = 0\n",
    "        iterator = iterator + 1\n",
    "        sum = 0\n",
    "        \n",
    "        X = np.vstack(X_list)\n",
    "        y = np.vstack(y_list)\n",
    "        \n",
    "        # Perform prediction using the current predictor\n",
    "        prediction = clf.predict(X)\n",
    "        y_pred = (prediction > 0.5)\n",
    "        \n",
    "        # Calculate the F2-Score\n",
    "        current_f2_score = metrics.fbeta_score(y_pred, y, average=None, beta=2)\n",
    "        scores.append(current_f2_score[1])\n",
    "          \n",
    "        X_list = []\n",
    "        y_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch retrain scenario\n",
    "# Initialize\n",
    "sum = 0\n",
    "counter = 0\n",
    "iterator = 0\n",
    "X_list = []\n",
    "y_list = []\n",
    "\n",
    "# Initial training\n",
    "stream.restart()\n",
    "X, y = stream.next_sample(init_training)\n",
    "clf = get_clf()\n",
    "df_sampled = sample(X,y)\n",
    "clf.fit(df_sampled.iloc[:,:-1],df_sampled.iloc[:,-1:],batch_size = batch_size,epochs = 1)\n",
    "\n",
    "scores_retraining = []\n",
    "\n",
    "#Continuous Training\n",
    "while (stream.n_remaining_samples() > 1):\n",
    "    # get next sample from the stream\n",
    "    X, y = stream.next_sample(1)\n",
    "    X_list.append(X)\n",
    "    y_list.append(y)\n",
    "    \n",
    "    # Sum up the samples of the late class\n",
    "    sum = sum+y[0]\n",
    "    counter = counter + 1\n",
    "    \n",
    "    # Check if at least C samples per class are present\n",
    "    if (sum >= C) & (counter-sum >= C):\n",
    "        counter = 0\n",
    "        iterator = iterator + 1\n",
    "        sum = 0\n",
    "        print(counter)\n",
    "        print(iterator)\n",
    "        \n",
    "        X = np.vstack(X_list)\n",
    "        y = np.vstack(y_list)\n",
    "        \n",
    "        # Perform prediction using the current predictor\n",
    "        prediction = clf.predict(X)\n",
    "        y_pred = (prediction > 0.5)\n",
    "        \n",
    "        # Calculate the F2-Score on the data sample\n",
    "        current_f2_score = metrics.fbeta_score(y_pred, y, average=None, beta=2)\n",
    "        scores_retraining.append(current_f2_score[1])\n",
    "        \n",
    "        # Initialize a new classifier and train on the last sample\n",
    "        clf = get_clf()    \n",
    "        df_sampled = sample(X,y)\n",
    "        clf.fit(df_sampled.iloc[:,:-1],df_sampled.iloc[:,-1:], batch_size = batch_size, epochs = epochs)\n",
    "        \n",
    "        X_list = []\n",
    "        y_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partial fit scenario\n",
    "# Initilaize\n",
    "sum = 0\n",
    "counter = 0\n",
    "iterator = 0\n",
    "X_list = []\n",
    "y_list = []\n",
    "\n",
    "# Initial training\n",
    "stream.restart()\n",
    "X, y = stream.next_sample(init_training)\n",
    "clf = get_clf()\n",
    "df_sampled = sample(X,y)\n",
    "clf.fit(df_sampled.iloc[:,:-1],df_sampled.iloc[:,-1:],batch_size = batch_size,epochs = 1)\n",
    "\n",
    "scores_partial_fit = []\n",
    "\n",
    "#Continuous Training\n",
    "while (stream.n_remaining_samples() > 1):\n",
    "    # get next sample from the stream\n",
    "    X, y = stream.next_sample(1)\n",
    "    X_list.append(X)\n",
    "    y_list.append(y)\n",
    "    \n",
    "    # Sum up the samples of the late class\n",
    "    sum = sum+y[0]\n",
    "    counter = counter + 1\n",
    "    \n",
    "    # Check if at least C samples per class are present\n",
    "    if (sum >= C) & (counter-sum >= C):\n",
    "        counter = 0\n",
    "        iterator = iterator + 1\n",
    "        sum = 0\n",
    "        print(counter)\n",
    "        print(iterator)\n",
    "        \n",
    "        X = np.vstack(X_list)\n",
    "        y = np.vstack(y_list)\n",
    "        \n",
    "        # Perform prediction using the current predictor\n",
    "        prediction = clf.predict(X)\n",
    "        y_pred = (prediction > 0.5)\n",
    "        \n",
    "        # Calculate the F2-Score on the data sample\n",
    "        current_f2_score = metrics.fbeta_score(y_pred, y, average=None, beta=2)\n",
    "        scores_partial_fit.append(current_f2_score[1])\n",
    "        \n",
    "        # Update thecurrent predictor with the new samples\n",
    "        df_sampled = sample(X,y)\n",
    "        clf.fit(df_sampled.iloc[:,:-1],df_sampled.iloc[:,-1:], batch_size = batch_size, epochs = epochs)\n",
    "        \n",
    "        X_list = []\n",
    "        y_list = []      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Active learning scenario\n",
    "# Initialize\n",
    "sum = 0\n",
    "counter = 0\n",
    "iterator = 0\n",
    "X_list = []\n",
    "y_list = []\n",
    "\n",
    "# Set initial values for PH scenarios (lambdas)\n",
    "sample_count_005 = 1\n",
    "ph_mean_005 = 0\n",
    "ph_sum_005 = 0\n",
    "\n",
    "sample_count_01 = 1\n",
    "ph_mean_01 = 0\n",
    "ph_sum_01 = 0\n",
    "\n",
    "sample_count_025 = 1\n",
    "ph_mean_025 = 0\n",
    "ph_sum_025 = 0\n",
    "\n",
    "sample_count_1 = 1\n",
    "ph_mean_1 = 0\n",
    "ph_sum_1 = 0\n",
    "\n",
    "sample_count_2 = 1\n",
    "ph_mean_2 = 0\n",
    "ph_sum_2 = 0\n",
    "\n",
    "sample_count_5 = 1\n",
    "ph_mean_5 = 0\n",
    "ph_sum_5 = 0\n",
    "\n",
    "sample_count_10 = 1\n",
    "ph_mean_10 = 0\n",
    "ph_sum_10 = 0\n",
    "\n",
    "# Threshold for change detection\n",
    "ph_lambda_005 = 0.05\n",
    "ph_sum_list_005 = []\n",
    "ph_score_list_005 = []\n",
    "\n",
    "ph_lambda_01 = 0.1\n",
    "ph_sum_list_01 = []\n",
    "ph_score_list_01 = []\n",
    "\n",
    "ph_lambda_025 = 0.25\n",
    "ph_sum_list_025 = []\n",
    "ph_score_list_025 = []\n",
    "\n",
    "ph_lambda_1 = 1\n",
    "ph_sum_list_1 = []\n",
    "ph_score_list_1 = []\n",
    "\n",
    "ph_lambda_2 = 2\n",
    "ph_sum_list_2 = []\n",
    "ph_score_list_2 = []\n",
    "\n",
    "ph_lambda_5 = 5\n",
    "ph_sum_list_5 = []\n",
    "ph_score_list_5 = []\n",
    "\n",
    "ph_lambda_10 = 10\n",
    "ph_sum_list_10 = []\n",
    "ph_score_list_10 = []\n",
    "\n",
    "#Pretrain the initial classifiers\n",
    "stream.restart()\n",
    "X, y = stream.next_sample(init_training)\n",
    "df_sampled = sample(X,y)\n",
    "\n",
    "clf_005 = get_clf()\n",
    "clf_005.fit(df_sampled.iloc[:,:-1],df_sampled.iloc[:,-1:],batch_size = batch_size,epochs= epochs)\n",
    "\n",
    "clf_01 = get_clf()\n",
    "clf_01.fit(df_sampled.iloc[:,:-1],df_sampled.iloc[:,-1:],batch_size = batch_size,epochs= epochs)\n",
    "\n",
    "clf_025 = get_clf()\n",
    "clf_025.fit(df_sampled.iloc[:,:-1],df_sampled.iloc[:,-1:],batch_size = batch_size,epochs= epochs)\n",
    "\n",
    "clf_1 = get_clf()\n",
    "clf_1.fit(df_sampled.iloc[:,:-1],df_sampled.iloc[:,-1:],batch_size = batch_size,epochs= epochs)\n",
    "\n",
    "clf_2 = get_clf()\n",
    "clf_2.fit(df_sampled.iloc[:,:-1],df_sampled.iloc[:,-1:],batch_size = batch_size,epochs= epochs)\n",
    "\n",
    "clf_5 = get_clf()\n",
    "clf_5.fit(df_sampled.iloc[:,:-1],df_sampled.iloc[:,-1:],batch_size = batch_size,epochs= epochs)\n",
    "\n",
    "clf_10 = get_clf()\n",
    "clf_10.fit(df_sampled.iloc[:,:-1],df_sampled.iloc[:,-1:],batch_size = batch_size,epochs= epochs)\n",
    "\n",
    "# Get next sample from stream\n",
    "while (stream.n_remaining_samples() > 1):\n",
    "    X, y = stream.next_sample(1)\n",
    "    X_list.append(X)\n",
    "    y_list.append(y)\n",
    "    \n",
    "    # Capture number of samples from the late class\n",
    "    sum = sum+y[0]\n",
    "    counter = counter + 1\n",
    "    \n",
    "    # If at least C instances per class are present\n",
    "    if (sum >= C) & (counter-sum >= C):\n",
    "        counter = 0\n",
    "        iterator = iterator + 1\n",
    "        sum = 0\n",
    "        print(counter)\n",
    "        print(iterator)\n",
    "        \n",
    "        X = np.vstack(X_list)\n",
    "        y = np.vstack(y_list)\n",
    "        df_sampled = sample(X,y)\n",
    "        \n",
    "        # Predict on the current classifier\n",
    "        prediction = clf_005.predict(X)\n",
    "        y_pred = (prediction > 0.5)\n",
    "        \n",
    "        # Calculate the F2-Score\n",
    "        current_f2_score = metrics.fbeta_score(y_pred, y, average=None, beta=2)\n",
    "        ph_score_list_005.append(current_f2_score[1])\n",
    "        \n",
    "        # Calculate the PH statistics\n",
    "        ph_mean_005, ph_sum_005, ph_sum_list_005, statistic_max, statistic_min = compute_ph_statistics(ph_mean_005, ph_sum_005, current_f2_score[1], ph_sum_list_005)\n",
    "        sample_count_005 += 1\n",
    "    \n",
    "        # Check, if a retraining or update is recommended\n",
    "        if ((statistic_max > ph_lambda_005) | (statistic_min > ph_lambda_005)):\n",
    "            ph_mean_005, ph_sum_005, ph_sum_list_005, sample_count_005 = reset_values()\n",
    "            print('Drift, No. of iterations:', iterator)\n",
    "            \n",
    "            # Get a new instance of the classifier\n",
    "            clf_005 = get_clf()\n",
    "\n",
    "        #Update/train the current classifier on the last samples from the stream\n",
    "        clf_005.fit(df_sampled.iloc[:,:-1],df_sampled.iloc[:,-1:],batch_size = batch_size,epochs = epochs)\n",
    "        \n",
    "        # Repeat same procedure for different lambdas\n",
    "        prediction = clf_01.predict(X)\n",
    "        y_pred = (prediction > 0.5)\n",
    "        current_f2_score = metrics.fbeta_score(y_pred, y, average=None, beta=2)\n",
    "        ph_score_list_01.append(current_f2_score[1])\n",
    "        \n",
    "        ph_mean_01, ph_sum_01, ph_sum_list_01, statistic_max, statistic_min = compute_ph_statistics(ph_mean_01, ph_sum_01, current_f2_score[1], ph_sum_list_01)\n",
    "        sample_count_01 += 1\n",
    "    \n",
    "        if ((statistic_max > ph_lambda_01) | (statistic_min > ph_lambda_01)):\n",
    "            ph_mean_01, ph_sum_01, ph_sum_list_01, sample_count_01 = reset_values()\n",
    "            print('Drift, No. of iterations:', iterator)\n",
    "            clf_01 = get_clf()\n",
    "\n",
    "        clf_01.fit(df_sampled.iloc[:,:-1],df_sampled.iloc[:,-1:],batch_size = batch_size,epochs = epochs)\n",
    "\n",
    "        \n",
    "        prediction = clf_025.predict(X)\n",
    "        y_pred = (prediction > 0.5)\n",
    "        current_f2_score = metrics.fbeta_score(y_pred, y, average=None, beta=2)\n",
    "        ph_score_list_025.append(current_f2_score[1])\n",
    "        \n",
    "        ph_mean_025, ph_sum_025, ph_sum_list_025, statistic_max, statistic_min = compute_ph_statistics(ph_mean_025, ph_sum_025, current_f2_score[1], ph_sum_list_025)\n",
    "        sample_count_025 += 1\n",
    "    \n",
    "        if ((statistic_max > ph_lambda_025) | (statistic_min > ph_lambda_025)):\n",
    "            ph_mean_025, ph_sum_025, ph_sum_list_025, sample_count_025 = reset_values()\n",
    "            print('Drift, No. of iterations:', iterator)\n",
    "            clf_025 = get_clf()\n",
    "\n",
    "        clf_025.fit(df_sampled.iloc[:,:-1],df_sampled.iloc[:,-1:],batch_size = batch_size,epochs = epochs)\n",
    "\n",
    "\n",
    "        prediction = clf_1.predict(X)\n",
    "        y_pred = (prediction > 0.5)\n",
    "        current_f2_score = metrics.fbeta_score(y_pred, y, average=None, beta=2)\n",
    "        ph_score_list_1.append(current_f2_score[1])\n",
    "        \n",
    "        ph_mean_1, ph_sum_1, ph_sum_list_1, statistic_max, statistic_min = compute_ph_statistics(ph_mean_1, ph_sum_1, current_f2_score[1], ph_sum_list_1)\n",
    "        sample_count_1 += 1\n",
    "    \n",
    "        if ((statistic_max > ph_lambda_1) | (statistic_min > ph_lambda_1)):\n",
    "            ph_mean_1, ph_sum_1, ph_sum_list_1, sample_count_1 = reset_values()\n",
    "            print('Drift, No. of iterations:', iterator)\n",
    "            clf_1 = get_clf()\n",
    "\n",
    "        clf_1.fit(df_sampled.iloc[:,:-1],df_sampled.iloc[:,-1:],batch_size = batch_size,epochs = epochs)\n",
    "\n",
    "\n",
    "        prediction = clf_2.predict(X)\n",
    "        y_pred = (prediction > 0.5)\n",
    "        current_f2_score = metrics.fbeta_score(y_pred, y, average=None, beta=2)\n",
    "        ph_score_list_2.append(current_f2_score[1])\n",
    "        \n",
    "        ph_mean_2, ph_sum_2, ph_sum_list_2, statistic_max, statistic_min = compute_ph_statistics(ph_mean_2, ph_sum_2, current_f2_score[1], ph_sum_list_2)\n",
    "        sample_count_2 += 1\n",
    "    \n",
    "        if ((statistic_max > ph_lambda_2) | (statistic_min > ph_lambda_2)):\n",
    "            ph_mean_2, ph_sum_2, ph_sum_list_2, sample_count_2 = reset_values()\n",
    "            print('Drift, No. of iterations:', iterator)\n",
    "            clf_2 = get_clf()\n",
    "\n",
    "        clf_2.fit(df_sampled.iloc[:,:-1],df_sampled.iloc[:,-1:],batch_size = batch_size,epochs = epochs)\n",
    "        \n",
    "        \n",
    "        prediction = clf_5.predict(X)\n",
    "        y_pred = (prediction > 0.5)\n",
    "        current_f2_score = metrics.fbeta_score(y_pred, y, average=None, beta=2)\n",
    "        ph_score_list_5.append(current_f2_score[1])\n",
    "        \n",
    "        ph_mean_5, ph_sum_5, ph_sum_list_5, statistic_max, statistic_min = compute_ph_statistics(ph_mean_5, ph_sum_5, current_f2_score[1], ph_sum_list_5)\n",
    "        sample_count_5 += 1\n",
    "    \n",
    "        if ((statistic_max > ph_lambda_5) | (statistic_min > ph_lambda_5)):\n",
    "            ph_mean_5, ph_sum_5, ph_sum_list_5, sample_count_5 = reset_values()\n",
    "            print('Drift, No. of iterations:', iterator)\n",
    "            clf_5 = get_clf()\n",
    "\n",
    "        clf_5.fit(df_sampled.iloc[:,:-1],df_sampled.iloc[:,-1:],batch_size = batch_size,epochs = epochs)\n",
    "        \n",
    "        \n",
    "        prediction = clf_10.predict(X)\n",
    "        y_pred = (prediction > 0.5)\n",
    "        current_f2_score = metrics.fbeta_score(y_pred, y, average=None, beta=2)\n",
    "        ph_score_list_10.append(current_f2_score[1])\n",
    "        \n",
    "        ph_mean_10, ph_sum_10, ph_sum_list_10, statistic_max, statistic_min = compute_ph_statistics(ph_mean_10, ph_sum_10, current_f2_score[1], ph_sum_list_10)\n",
    "        sample_count_10 += 1\n",
    "    \n",
    "        if ((statistic_max > ph_lambda_10) | (statistic_min > ph_lambda_10)):\n",
    "            ph_mean_10, ph_sum_10, ph_sum_list_10, sample_count_10 = reset_values()\n",
    "            print('Drift, No. of iterations:', iterator)\n",
    "            clf_10 = get_clf()\n",
    "\n",
    "        clf_10.fit(df_sampled.iloc[:,:-1],df_sampled.iloc[:,-1:],batch_size = batch_size,epochs = epochs)\n",
    "        \n",
    "        X_list = []\n",
    "        y_list = []  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ph_score_list_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare F2-Scores for plotting\n",
    "data = pd.DataFrame()\n",
    "data['No Online Learning'] = scores[1:]\n",
    "data['Batch Retraining'] = scores_retraining\n",
    "data['Incremental Learning'] = scores_partial_fit\n",
    "data['Active Decision Learning'] = ph_score_list_5\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the data for the different scenarios\n",
    "data.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot all scenarios and print mean F2-Scores\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(scores_retraining, label = 'Entire Retraining for every batch')\n",
    "plt.plot(scores_partial_fit, label = 'Partial Fit for every batch')\n",
    "plt.plot(ph_score_list_005, label = '\"Smart\" Retraining: PH-Change Detection 0,05')\n",
    "plt.plot(ph_score_list_01, label = '\"Smart\" Retraining: PH-Change Detection 0,1')\n",
    "plt.plot(ph_score_list_025, label = '\"Smart\" Retraining: PH-Change Detection 0,25')\n",
    "plt.plot(ph_score_list_1, label = '\"Smart\" Retraining: PH-Change Detection 1')\n",
    "plt.plot(ph_score_list_2, label = '\"Smart\" Retraining: PH-Change Detection 2')\n",
    "plt.plot(ph_score_list_5, label = '\"Smart\" Retraining: PH-Change Detection 5')\n",
    "plt.plot(ph_score_list_10, label = '\"Smart\" Retraining: PH-Change Detection 10')\n",
    "plt.plot(scores, label = 'No Retraining')\n",
    "plt.title('Development of F2-Score of late-class over time')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "filepath = params.filepath_project_folder + '\\concept_drift_f1_scores.png'\n",
    "plt.savefig(filepath, bbox_inches = 'tight')\n",
    "\n",
    "print('Mean accuracy retraining', np.mean(scores_retraining))\n",
    "print('Mean accuracy partial fit', np.mean(scores_partial_fit))\n",
    "print('Mean accuracy single training', np.mean(scores))\n",
    "print('Mean accuracy ph training 0,05', np.mean(ph_score_list_005))\n",
    "print('Mean accuracy ph training 0,1', np.mean(ph_score_list_01))\n",
    "print('Mean accuracy ph training 0,25', np.mean(ph_score_list_025))\n",
    "print('Mean accuracy ph training 1', np.mean(ph_score_list_1))\n",
    "print('Mean accuracy ph training 2', np.mean(ph_score_list_2))\n",
    "print('Mean accuracy ph training 5', np.mean(ph_score_list_5))\n",
    "print('Mean accuracy ph training 10', np.mean(ph_score_list_10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
