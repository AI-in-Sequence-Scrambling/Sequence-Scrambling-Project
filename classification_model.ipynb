{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required python packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import importlib\n",
    "import sklearn.metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required helper functions\n",
    "from helper_functions import methods_prediction as pred_meth\n",
    "from helper_functions import methods_sampling as sampling_meth\n",
    "from helper_functions import keras_NN as keras\n",
    "from helper_functions import methods_prediction as pred_meth\n",
    "from helper_functions import control_methods as meth_control\n",
    "from helper_functions import feature_engineering as feature_eng\n",
    "from helper_functions import methods_PrNrn as meth\n",
    "from helper_functions import test_grids\n",
    "from helper_functions import parametergrids\n",
    "from helper_functions import params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the datasets to test/predict on\n",
    "df_sqa = pd.read_csv(params.filepath_project_folder + '\\SQA_full_prepro_data.csv', index_col=0)\n",
    "df_features_full = pd.read_csv(params.filepath_project_folder + '\\\\features_full.csv', index_col=0)\n",
    "df_features_full_reduced = pd.read_csv(params.filepath_project_folder + '\\\\features_full_reduced.csv', index_col=0)\n",
    "df_features_kaco = pd.read_csv(params.filepath_project_folder + '\\\\features_kaco.csv', index_col=0)\n",
    "df_features_kaco_reduced = pd.read_csv(params.filepath_project_folder + '\\\\features_kaco_reduced.csv', index_col=0)\n",
    "\n",
    "# Engineer additional datsets to test/predict on\n",
    "df_features_kaco_noAudit_noMess = feature_eng.remove_audit(feature_eng.remove_mess(df_features_kaco))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the datasets to iterate through feature params and provide names for the datasets\n",
    "\n",
    "feature_dfs = [df_features_kaco_reduced]\n",
    "feature_dfs_names = ['df_features_kaco_reduced']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the paramtergrids for the meta paramters and the model parameters\n",
    "importlib.reload(test_grids)\n",
    "importlib.reload(parametergrids)\n",
    "\n",
    "model_paramgrid = test_grids.paramgrid_binary_RF\n",
    "meta_paramgrid = test_grids.meta_paramgrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty dataframe to store the prediction results\n",
    "df_results = pd.DataFrame(columns=['feature_set', 'model', 'cut_off_high', 'cut_off_low', 'delete', 'threshhold_late', 'target_col', 'sampling', \n",
    "                                   'sample_frac', 'cv_num', 'pred_certainty', 'model_params', 'y_test', 'y_pred', 'f1', 'f2', 'precision', 'recall',\n",
    "                                   'cm', 'timestamp'])\n",
    "\n",
    "df_results_bin_NN = pd.DataFrame(columns=['layer_depth', 'layer_architecture', 'input_activation_function', \n",
    "                                       'input_neurons', 'dropout', 'hidden_neurons', 'hidden_activation_function', \n",
    "                                       'output_activation_function', 'output_neurons', 'optimizer', 'epochs', \n",
    "                                       'batch_size'])\n",
    "\n",
    "df_results_bin_XGB = pd.DataFrame(columns=['booster', 'eta', 'gamma', \n",
    "                                       'max_depth', 'lambda', 'alpha', 'tree_method', \n",
    "                                       'num_parallel_tree'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the prediction\n",
    "timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "importlib.reload(meth_control)\n",
    "\n",
    "# Choose the prediction model to use\n",
    "model = 'binary_RF'\n",
    "\n",
    "\n",
    "# Define save parameters\n",
    "if model == 'binary_RF':\n",
    "    model_id = '\\RFClf'\n",
    "    filepath_mod = params.filepath_project_folder + '\\prediction_models\\binary_classifier_RF'\n",
    "    filepath_res = params.filepath_project_folder + '\\prediction_results\\binary_classifier_RF'\n",
    "    \n",
    "if model == 'binary_NN':\n",
    "    model_id = '\\NNClf'\n",
    "\n",
    "    filepath_mod = params.filepath_project_folder + '\\prediction_models\\binary_classifier_NN'\n",
    "    filepath_res = params.filepath_project_folder + '\\prediction_results\\binary_classifier_NN'\n",
    "    \n",
    "if model == 'binary_XGB':\n",
    "    model_id = '\\XGBClf'\n",
    "\n",
    "    filepath_mod = params.filepath_project_folder + '\\prediction_models\\binary_classifier_XGB'\n",
    "    filepath_res = params.filepath_project_folder + '\\prediction_results\\binary_classifier_XGB'\n",
    "    \n",
    "\n",
    "# Initiate counter\n",
    "c = 0\n",
    "feature_set_counter = 0\n",
    "\n",
    "print(time.strftime(\"%Y%m%d-%H%M%S\"))\n",
    "\n",
    "# Iterate over the datasets to compare\n",
    "for df_features in feature_dfs:\n",
    "    \n",
    "    feature_set_counter = feature_set_counter+1\n",
    "    print('- Dataset ' + str(feature_set_counter) + '/' + str(len(feature_dfs)))\n",
    "    \n",
    "    # Iterate over the meta-parametergrid, e.g. sampling algorithms\n",
    "    for i in range (0, len(meta_paramgrid)):\n",
    "        print('- Meta-Parameter run ' + str(i+1) + '/' + str(len(meta_paramgrid))) \n",
    "        \n",
    "        # Iterate over the model parameter grid (model hyperparameter)\n",
    "        for j in range (0, len(model_paramgrid)):\n",
    "            print('- Model-Parameter run ' + str(j+1) + '/' + str(len(model_paramgrid)))\n",
    "            \n",
    "            # Check which model to use\n",
    "            if model == 'binary_NN':\n",
    "                \n",
    "                # Call method to perform the classification task\n",
    "                trained_models, f1_scores, f2_scores, precision_scores, recall_scores, cms, y_preds, y_tests, model_results = meth_control.perform_binary_classification(\n",
    "                                df_features, df_sqa, meta_paramgrid[i], model_paramgrid[j])\n",
    "                \n",
    "                # Store results\n",
    "                df_results_bin_NN.loc[c] = [model_paramgrid[j]['layer_depth'], model_paramgrid[j]['layer_architecture'], \n",
    "                                        model_paramgrid[j]['input_activation_function'], \n",
    "                                        model_paramgrid[j]['input_neurons'], \n",
    "                                        model_paramgrid[j]['dropout'], model_paramgrid[j]['hidden_neurons'], \n",
    "                                        model_paramgrid[j]['hidden_activation_function'], \n",
    "                                        model_paramgrid[j]['output_activation_function'], \n",
    "                                        model_paramgrid[j]['output_neurons'], model_paramgrid[j]['optimizer'], \n",
    "                                        model_paramgrid[j]['epochs'], model_paramgrid[j]['batch_size']]\n",
    "                \n",
    "            if model == 'binary_RF':           \n",
    "                \n",
    "                # Call method to perform the classification task\n",
    "                trained_models, f1_scores, f2_scores, precision_scores, recall_scores, cms, y_preds, y_tests, model_results = meth_control.perform_binary_classification_RF(\n",
    "                                df_features, df_sqa, meta_paramgrid[i], model_paramgrid[j])\n",
    "            \n",
    "            if model == 'binary_XGB':           \n",
    "                \n",
    "                # Call method to perform the classification task\n",
    "                trained_models, f1_scores, f2_scores, precision_scores, recall_scores, cms, y_preds, y_tests, model_results = meth_control.perform_binary_classification_XGBoost(\n",
    "                                df_features, df_sqa, meta_paramgrid[i], model_paramgrid[j])      \n",
    "                \n",
    "                df_results_bin_XGB.loc[c] = [model_paramgrid[j]['booster'], model_paramgrid[j]['eta'], \n",
    "                                        model_paramgrid[j]['gamma'], \n",
    "                                        model_paramgrid[j]['max_depth'], \n",
    "                                        model_paramgrid[j]['lambda'], model_paramgrid[j]['alpha'], \n",
    "                                        model_paramgrid[j]['tree_method'], \n",
    "                                        model_paramgrid[j]['num_parallel_tree']]\n",
    "                \n",
    "            # Save results in prepared DataFrame\n",
    "            df_results.loc[c] = [feature_dfs_names[feature_set_counter-1], model, meta_paramgrid[i]['cut_off_high'], \n",
    "                                         meta_paramgrid[i]['cut_off_low'], meta_paramgrid[i]['delete'],\n",
    "                                         meta_paramgrid[i]['threshhold_late'], meta_paramgrid[i]['target_col'], \n",
    "                                         meta_paramgrid[i]['sampling'], meta_paramgrid[i]['sample_frac'], \n",
    "                                         meta_paramgrid[i]['cv_num'], meta_paramgrid[i]['pred_certainty'],\n",
    "                                         model_paramgrid[j], \n",
    "                                         y_tests, y_preds, f1_scores, f2_scores,\n",
    "                                         precision_scores, recall_scores, cms, time.strftime(\"%Y%m%d-%H%M%S\")]\n",
    "            c = c+1\n",
    "            \n",
    "print(time.strftime(\"%Y%m%d-%H%M%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save raw results\n",
    "\n",
    "filename = model_id + timestr + '_results.csv'\n",
    "df_results.to_csv(filepath_res + filename)\n",
    "\n",
    "# Save model parameter results\n",
    "if model == 'binary_NN':\n",
    "    filename = model_id + timestr + '_results_binary_NN.csv'\n",
    "    df_results_bin_NN.to_csv(filepath_res + filename)\n",
    "    \n",
    "if model == 'binary_XGBoost':  \n",
    "    filename = model_id + timestr + '_results_binary_XGB.csv'\n",
    "    df_results_bin_XGB.to_csv(filepath_res + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare results for plotting\n",
    "for cat in [0, 1]:\n",
    "    for col in ['f1', 'f2', 'recall', 'precision']:\n",
    "        new_col = col + '_' + str(cat)\n",
    "        df_results[new_col] = 99.99\n",
    "        for i in range (0, len(df_results)):\n",
    "            new_val = 0\n",
    "            for j in range (0, df_results['cv_num'][i]):\n",
    "                new_val = new_val + df_results[col][i][j][cat]\n",
    "            new_val = new_val/df_results['cv_num'][i]\n",
    "            df_results.at[i, new_col] = new_val\n",
    "            \n",
    "filename = model_id + timestr + '_results_edited.csv'\n",
    "df_results.to_csv(filepath_res + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results\n",
    "f = plt.figure()\n",
    "\n",
    "plt.title('Model Performance', color='black')\n",
    "\n",
    "df_results.plot(x='model', y=['f2_0', 'f2_1', 'f1_0', 'f1_1'], kind='line', ax=f.gca(), figsize=(16,10))\n",
    "\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1.0, 0.5))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
